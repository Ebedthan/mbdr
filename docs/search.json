[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Modélisation des données biologiques avec R",
    "section": "",
    "text": "Bienvenue\nCe livre est le manuel compagnon de la formation modélisation de données biologiques organisée par le service innovation et transfert de technologie des fablab agritech à destination des élèves ingénieurs agronomes ou biologiques de l’Institut National Polytechnique Félix Houphouët-Boigny.\nLa formation se déroule typiquement sur cinq jours et réuni autour de 10 étudiants.\nCe manuel est et sera toujours gratuit, sous licence CC BY-NC-ND 3.0."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Ce que vous allez apprendre\nAu cours de cette formation nous aborderons les concepts suivants:\nCe livre est un manuel de formation à destination des ingénieurs en sciences agronomiques ou biologiques en fin de cycle (3e année).\nIl se veut pratique et facile à aborder tout en n’hésitant pas à revenir sur les concepts mathématiques avancés pour solidifier les fondements mathématiques des participants.\nCe manuel est utilisé lors de la formation organisée par le biais du service innovation et transfert de technologie des fablabs agritech de l’Institut National Polytechnique Félix Houphouët-Boigny de Côte d’Ivoire.\nCette formation n’est pas une formation à l’utilisation de R. Nous n’aborderons donc pas les notions basiques de son utilisation. Nous ferons cependant l’effort d’apporter de l’aide ou des informations pour chaque fonction utilisée. Nous n’aborderont pas aussi les thèmes des tests d’hypothèses, de la conception d’expérience, de la manipulation des données, de la visualisation des données ou de la programmation littérale avec R.\nCes thèmes sont abordés dans d’autres formations que nous organisons.\nNous avons choisi de faire cette formation en utilisant les fonction R basiques et non sous l’aspect de la philosophie tidyverse (pour laquelle nous consacrons une autre formation). Ce choix est fait pour garder l’attention des étudiants dirigées exclusivement sur la compréhension des concepts statistiques présentés et à leur mise en pratique avec R.\nNous avons fait quelques suppositions sur ce que vous savez déjà pour tirer le meilleur parti de cette formation. Vous devez avoir des connaissances générales en calcul et il est utile que vous ayez déjà une certaine expérience de la programmation de base. Si vous n’avez jamais programmé auparavant, Hands on Programming with R pourrait être un outil précieux.\nVous avez besoin de quatre éléments pour exécuter le code de ce livre : R, RStudio, un certains nombre de jeu de données. Les packages sont les unités fondamentales du code R reproductible. Ils comprennent des fonctions réutilisables, de la documentation décrivant comment les utiliser et des exemples de données."
  },
  {
    "objectID": "intro.html#r",
    "href": "intro.html#r",
    "title": "Introduction",
    "section": "R",
    "text": "R\nPour télécharger R, rendez-vous sur CRAN, le réseau complet d’archives R, https://cloud.r-project.org. Une nouvelle version majeure de R est publiée une fois par an, et il y a 2 à 3 versions mineures par an. C’est une bonne idée de faire des mises à jour régulièrement. La mise à jour peut être un peu fastidieuse, en particulier pour les versions majeures qui vous obligent à réinstaller tous vos paquets, mais la remettre à plus tard ne fait qu’empirer les choses. Nous recommandons R 4.2.0 ou une version ultérieure pour cette formation."
  },
  {
    "objectID": "intro.html#rstudio",
    "href": "intro.html#rstudio",
    "title": "Introduction",
    "section": "RStudio",
    "text": "RStudio\nRStudio est un environnement de développement intégré (IDE) pour la programmation R, que vous pouvez télécharger à partir de https://posit.co/download/rstudio-desktop/. RStudio est mis à jour plusieurs fois par an et vous informe automatiquement de la sortie d’une nouvelle version. C’est une bonne idée de faire des mises à jour régulières pour profiter des dernières et meilleures fonctionnalités. Pour ce livre, assurez-vous d’avoir au moins RStudio 2022.02.0.\nLorsque vous démarrez RStudio , vous voyez deux zones clés de l’interface : le volet de console et le volet de sortie. Pour une exécution du code ligne par ligne, il faut taper le code R dans le volet de la console et appuyer sur la touche Entrée pour l’exécuter. Cependant si l’on veut créer un fichier pour y saisir le code il est possible d’utiliser l’éditeur de texte incorporé."
  },
  {
    "objectID": "datasets.html#le-jeu-de-données-penguins",
    "href": "datasets.html#le-jeu-de-données-penguins",
    "title": "1  Présentation des jeux de données",
    "section": "1.1 Le jeu de données penguins",
    "text": "1.1 Le jeu de données penguins\n\n1.1.1 A propos\n\n\n\nFigure 1.1: Palmer penguins hex sticker (Artwork by allison_horst)\n\n\nLe jeu de données Penguins est un jeu de données collectées et mises à disposition par le Dr. Kristen Gorman et la station Palmer, Antarctica LTER, membre du Long Term Ecological Research Network (réseau de recherche écologique à long terme) et mise à disposition de la communauté R au travers du package palmerpenguins.\nLe jeu de données s’appelle penguins, mais fait références en français à des manchots et non à des pingouins. Pour rappel, il y a deux différences fondamentales entre les pingouins et les manchots: leur répartition géographique et leur (in)capacité à voler. Les pingouins vivent dans l’hémisphère nord et ils peuvent voler! Quant aux manchots, ils ne peuvent pas voler et ils vivent dans l’hémisphère sud. Cependant, lors de ce atelier nous allons faire reference a ce jeu de données en utilisant le terme penguins pour garder le nom original du jeu de données.\nLe jeu de données contient des données de 344 manchots. Il y a 3 espèces différentes de manchots dans ce jeu de données Figure 1.2, collectées sur 3 îles de l’archipel de Palmer, en Antarctique.\n\n\n\nFigure 1.2: Les espèces de manchots dans palmerpenguins\n\n\n\n\n1.1.2 Installation et description courte\nLe package est disponible sur le CRAN et peut être installé à partir de la console R en utilisant la commande ci-dessous:\n\ninstall.packages(\"palmerpenguins\")\n\nLe jeu de donnée est composé de 344 observations et de 8 variables:\n\nstr(penguins)\n\ntibble [344 × 8] (S3: tbl_df/tbl/data.frame)\n $ species          : Factor w/ 3 levels \"Adelie\",\"Chinstrap\",..: 1 1 1 1 1 1 1 1 1 1 ...\n $ island           : Factor w/ 3 levels \"Biscoe\",\"Dream\",..: 3 3 3 3 3 3 3 3 3 3 ...\n $ bill_length_mm   : num [1:344] 39.1 39.5 40.3 NA 36.7 39.3 38.9 39.2 34.1 42 ...\n $ bill_depth_mm    : num [1:344] 18.7 17.4 18 NA 19.3 20.6 17.8 19.6 18.1 20.2 ...\n $ flipper_length_mm: int [1:344] 181 186 195 NA 193 190 181 195 193 190 ...\n $ body_mass_g      : int [1:344] 3750 3800 3250 NA 3450 3650 3625 4675 3475 4250 ...\n $ sex              : Factor w/ 2 levels \"female\",\"male\": 2 1 1 NA 1 2 1 2 NA NA ...\n $ year             : int [1:344] 2007 2007 2007 2007 2007 2007 2007 2007 2007 2007 ...\n\n\nLes différentes variables sont l’espèce, l’île (lieu de collecte des données), la longueur du culmen (mm), la profondeur du culmen (mm), la longueur de la nageoire (mm), le poids (g), le sexe et l’année de l’étude. Le culmen est appelé bill dans le jeu de donnée. En zoologie, le culmen est l’arête dorsale de la mandibule supérieure des oiseaux Figure 1.3.\n\n\n\nFigure 1.3: Description du culmen des manchots\n\n\nPour rappel, la description complète du format du jeu de donnée est disponible directement dans R en utilisant la commande ?penguins."
  },
  {
    "objectID": "exploration.html#outils-graphiques",
    "href": "exploration.html#outils-graphiques",
    "title": "\n2  Exploration des données\n",
    "section": "\n2.1 Outils graphiques",
    "text": "2.1 Outils graphiques\n\n2.1.1 Boîte à moustache\nUn diagramme en boîte, ou boîte à moustaches, permet de visualiser la moyenne et la dispersion d’une variable univariée. Normalement, le point central d’un diagramme en boîte est la médiane, mais il peut également s’agir de la moyenne. Les quartiles 25% et 75% (Q25 et Q75) définissent les charnières (extrémités des boîtes), et la différence entre les charnières est appelée l’écart. Des lignes (ou moustaches) sont tracées à partir de chaque charnière jusqu’à 1,5 fois l’écart ou jusqu’à la valeur la plus extrême de l’écart, la plus petite étant retenue. Tous les points situés en dehors de ces valeurs sont normalement identifiés comme des valeurs aberrantes Figure 2.1.\n\n\nFigure 2.1: Boîte à moustache\n\n\n\n\n\n\n\nLa syntaxe générale pour créer la boîte à moustache d’une variable en utilisant base R est: boxplot(variable).\nL’aide complète de la fonction boxplot() est obtenue par la commande ?boxplot().\n\n\n\nEtudions la variable body_mass_g en représentant sa boîte à moustache.\n\nboxplot(penguins$body_mass_g, xlab=\"Masse (g)\")\n\n\n\n\nOn remarque qu’aucune valeur aberrante n’apparait de façon visible. De plus on observe que la médiane du poids des manchots se situent autour de 4000 g (on peut facilement confirmer cela en calculant la médiane median(penguins$body_mass_g)).\nOn peut alors être amenée à continuer l’exploration en étudiant le poids, cette fois-ci en étudiant la variable par espèce de manchot.\n\nboxplot(body_mass_g ~ species, data=penguins, ylab=\"Masse (g)\", xlab=NULL)\n\n\n\n\nLes boîte à moustaches representées nous permettent de nous rendre compte que l’espèce Gentoo a sensiblement une masse plus élevée que les deux autres. On pourra confirmer si cette différence est significative avec une analyse de variance. De plus, on observe la présence de quelques valeurs aberrantes chez l’espèce Chinstrap.\n\n2.1.2 Diagramme de points de Cleveland\nLes diagrammes de points de Cleveland sont utiles pour identifier les valeurs aberrantes et l’homogénéité.\nL’homogénéité signifie que la variance des données ne change pas le long des gradients. La violation de cette condition est appelée hétérogénéité et l’homogénéité est une hypothèse cruciale pour de nombreuses méthodes statistiques.\nLa valeur est présentée sur l’axe horizontal et l’ordre des points (tel qu’il est organisé par le programme) est présenté sur l’axe vertical.\n\n\n\n\n\n\nLa syntaxe pour générer un nuage de points avec base R est dotchart(variable). L’aide est disponible avec la commande ?dotchart().\n\n\n\nRepresentons le nuage de point de Cleveland avec pour but d’identifier une possible violation de l’homogénéité ou la présence de valeurs aberrantes. Le diagrammes à points est réalisé en utilisant différents symboles conditionnels à une variable explicative nominale qui est ici l’espèce.\n\ndotchart(penguins$body_mass_g, main=\"Masse (g)\", pch=as.numeric(penguins$species))\n\n\n\n\nTout point isolé à droite ou à gauche indique des valeurs aberrantes, mais dans cet jeu de données, en considérant l’ensemble du graphique aucun point n’est considéré comme aberrant, ce qui confirme notre observation de la boîte à moustache. Cependant comme observé plus haut, en prenant les points par groupe (chaque symbole représentant une espèce différente) on observe bien un groupe présentant des valeurs aberrantes.\n\n2.1.3 Histogramme\nUn histogramme montre le centre et la distribution des données et donne une indication de la normalité. Toutefois, l’application d’une transformation des données pour les faire correspondre à une distribution normale nécessite des précautions.\n\n# Subdivision du panel graphique\nlayout(matrix(c(1, 2, 1, 3), nrow = 2, byrow = TRUE))\n\n# Histrogramme de la masse pour l'ensemble des manchots\nhist(penguins$body_mass_g, main=\"Masse (g)\", xlab=NULL)\n\n# Histrogramme de la masse pour les males\nhist(penguins$body_mass_g[penguins$sex==\"male\"], main=\"Males\", xlab=NULL)\n# Histrogramme de la masse pour les femelles\nhist(penguins$body_mass_g[penguins$sex==\"female\"], main=\"Females\", xlab=NULL)\n\n\n\n\nLa forme de l’histogramme montre une certaine asymétrie et l’on pourrait être tenté d’appliquer une transformation. Cependant, un histogramme conditionnel donne une image assez différente. Dans un histogramme conditionnel, les données sont divisées en fonction d’une variable nominale et les histogrammes des sous-ensembles sont tracés côte-à-côte. A ce moment on obtient une figure tout autre montrant une bimodalité aussi bien chez les males que chez les femelles manchots. On a une différence claire du centre de la distribution et la pic initial de données observé sur le premier histogramme est grandement du aux femelles. Il faudrait donc explorer les effets du sexe sur le poids des manchots ainsi que les interactions avant d’envisager une transformation des données.\n\n2.1.4 QQ-plots\nUn graphique Quantile-Quantile (QQ-plots) est un outil graphique utilisé pour déterminer si les données suivent une distribution particulière. Le graphique QQ pour une distribution normale compare la distribution d’une variable donnée à la distribution gaussienne. Si les points obtenus se situent approximativement sur une ligne droite, on considère que la distribution des données est la même que celle d’une variable normalement distribuée.\nLe \\(p\\)-ème quantile \\(q\\) d’une variable aléatoire \\(y\\) est donnée par \\(F(q) = P(y \\leq q) = p\\). Si l’on souhaire savoir quelle valeur de \\(q\\) appartient à \\(p\\), on inverse la formule précédente pour obtenir \\(q = F^{-1}(p)\\). Supposons que nous avons cinq observations \\(Y_i\\) avec les valeurs 1, 2, 3, 4, 5. Par définition, le premier chiffre est le 0% percentile, le milieu est le 50% percentile et 5 est le 100% percentile. La différence entre un quantile et un percentile est un seulement le facteur 100. Les QQ-plots sont soit basés sur les percentiles ou typiquement sur les points quantiles de l’échantillon définis par \\((i-0.5)/n\\) où \\(i\\) varie de 1 à 5 et \\(n=5\\) dans notre example. Ainsi pour notre exemple, les points de quantiles de l’échantillon sont 0,1, 0,3, 0,5, 0,7 et 0,9. Ce sont les valeurs de \\(p\\) pour l’échantillon. Dans la séconde étape, ces quantiles de l’échantillon sont comparés à une distribution normale. Celà signifie que la fonction de densité \\(P(y\\leq q)\\) est désormais une fonction de densité normale et \\(F()\\) est désormais la fonction de répartition de la loi normale.\nLe QQ-plot est donc un graphique des valeurs de \\(Y_i\\) de l’échantillon comparés aux \\(q_i\\). On peut ajouter à ce graphique dans R, une ligne qui connecte les 25e et le 75e quartiles.\nNous appliquons dans le même temps une transformation des données pour visualiser laquelle produit le meilleur ajustement.\nIl est très souvent utilse de combiner les QQ-plots avec des transformations de puissance, qui est donnée par \\[ \\frac{Y^p - 1}{p}, \\forall p \\neq 0; log(Y) , p = 0\\]\nVeuillez noter que le \\(p\\) utilisé ici n’est pas le \\(p\\) utilisé pour décrire les quantiles. Il est aussi utile de comparer plusieurs QQ-plots pour différentes valeurs de \\(p\\).\n\n# Transformation racine carrée\nbmsq &lt;- sqrt(penguins$body_mass_g)\n# Transformation racine quatrième\nbmfq &lt;- penguins$body_mass_g^(0.25)\n# Transformation logarithmique\nbmlog &lt;- log(penguins$body_mass_g)\n\nDans le graphique ci-dessous, aucune transormation semble prendre le dessus sur l’autre.\n\nlayout(matrix(c(1, 2, 3, 4), nrow = 2, byrow = TRUE))\nqqnorm(penguins$body_mass_g, main=\"Aucune transformation (p=0)\")\nqqline(penguins$body_mass_g)\nqqnorm(bmsq, main=\"Racine carré (p=0.5)\")\nqqline(bmsq)\nqqnorm(bmfq, main=\"Racine quatrième (p=0.25)\")\nqqline(bmfq)\nqqnorm(bmlog, main=\"Logarithme (p=1)\")\nqqline(bmlog)\n\n\n\n\n\n2.1.5 Nuage de points\nJusqu’à présent, l’accent a été mis sur la détection des valeurs aberrantes, la vérification de la normalité et l’exploration d’ensembles de données associés à des variables explicatives nominales uniques. Les techniques suivantes s’intéressent aux relations entre plusieurs variables. Un nuage de points est un outil permettant de trouver une relation entre deux variables. Il représente une variable sur l’axe horizontal et une seconde variable sur l’axe vertical. Pour aider à visualiser la relation entre les variables, une ligne droite ou une courbe de lissage est souvent ajoutée au graphique.\n\nplot(penguins$flipper_length_mm, penguins$body_mass_g, xlab=\"Taille des nageoires\", ylab=\"Masse (g)\")\nm1 &lt;- lm(body_mass_g ~ flipper_length_mm, data=penguins)\nabline(m1)\n\n\n\n\n\n2.1.6 Pairplots\nSi vous avez plus de deux variables, vous pouvez produire une série de nuage de points : un pour chaque paire de variables. Cependant, le nombre de diagrammes augmente rapidement si vous avez plus de trois variables à explorer. Une meilleure approche, jusqu’à environ 10 variables explicatives, est le diagramme de paires encore appelée matrice de nuage de points. Ces diagrammes présentent plusieurs nuage de points par paire dans un seul graphique et peuvent être utilisés pour détecter les relations entre les variables et pour détecter la colinéarité.\n\n# penguins[3:6] sélectionne les variables bill_length_mm\n# bill_depth_mm, flipper_length_mm, body_mass_g\npairs(penguins[,3:6])\n\n\n\n\n\n2.1.7 Coplot\nUn coplot est un nuage de points conditionnel montrant la relation entre y et x, pour différentes valeurs d’une troisième variable z, voire d’une quatrième variable w. Les variables conditionnelles peuvent être nominales ou continues.\n\ncoplot(body_mass_g ~ flipper_length_mm | species, data = penguins)\n\n\n\n\n\n Missing rows: 4, 272 \n\n\n\n2.1.8 Diagrammes de conception et d’interaction\nLes diagrammes de conception et d’interaction sont un autre outil précieux pour explorer les ensembles de données avec des variables nominales et sont particulièrement utiles à utiliser avant d’appliquer la régression, la GLM, la modélisation mixte ou l’ANOVA. Ils permettent de visualiser (i) les différences entre les valeurs moyennes de la variable réponse pour différents niveaux de variables nominales et (ii) les interactions entre les variables explicatives.\n\nplot.design(body_mass_g ~ species + sex + island, data = penguins)\n\n\n\n\n\ninteraction.plot(penguins$species, penguins$sex, penguins$body_mass_g)\n\n\n\n\n\ninteraction.plot(penguins$sex, penguins$island, penguins$body_mass_g)"
  },
  {
    "objectID": "exploration.html#valeurs-aberrantes-transformations-et-standardisation",
    "href": "exploration.html#valeurs-aberrantes-transformations-et-standardisation",
    "title": "\n2  Exploration des données\n",
    "section": "\n2.2 Valeurs aberrantes, transformations et standardisation",
    "text": "2.2 Valeurs aberrantes, transformations et standardisation\n\n2.2.1 Valeurs aberrantes\nUne valeur aberrante est un point de données qui, en raison de sa valeur extrême par rapport au reste de l’ensemble de données, peut influencer incorrectement une analyse. La première question qui se pose est donc la suivante : « Comment identifier une valeur aberrante ? Une approche simple pourrait consister à quantifier tout ce qui est aberrant au-delà d’une certaine distance par rapport au centre des données.\n\n2.2.2 Transformation\nIl existe de nombreuses raisons de transformer les données, mais c’est généralement parce que les données présentent des valeurs extrêmes aberrantes et des distributions non normales. La transformation des données (sur les variables de réponse) sera également nécessaire lorsque vous prévoyez d’utiliser l’analyse discriminante et qu’il existe des preuves évidentes (par exemple, en utilisant un diagramme en pointillés de Cleveland) de l’hétérogénéité.\nDe plus, le choix de la transformation est influencée par le choix de l’analyse de suivi. Pour certaines techniques, telles que les arbres de classification ou de régression, la transformation des variables explicatives ne change rien aux résultats. Cependant, la plupart des techniques peuvent nécessiter une certaine transformation des données brutes avant l’analyse.\n\n2.2.3 Standardisation\nSi les variables comparées proviennent d’échelles très différentes, comme la comparaison des taux de croissance de petites espèces de poissons avec ceux de grandes espèces de poissons, la standardisation (conversion de toutes les variables à la même échelle) peut être une option. Toutefois, cela dépend de la technique statistique utilisée."
  },
  {
    "objectID": "regression.html#regression-linéaire-bivariée",
    "href": "regression.html#regression-linéaire-bivariée",
    "title": "3  Regression linéaire",
    "section": "3.1 Regression linéaire bivariée",
    "text": "3.1 Regression linéaire bivariée\nLe modèle de régression linéaire bivarié (c’est-à-dire à deux variables) est donné par la formule suivante:\n\\[ Y_i = \\alpha + X_i\\beta + \\epsilon_i\\]\noù α est l’ordonnée à l’origine, β est la pente et ε est le résidu, ou l’information qui n’est pas expliquée par le modèle. Ce modèle est basé sur l’ensemble de la population, mais comme expliqué ci-dessus, nous ne disposons que d’un échantillon de la population, et nous devons d’une manière ou d’une autre utiliser les données de cet échantillon pour estimer les valeurs de α et de β pour l’ensemble de la population. Pour ce faire, nous devons faire quatre hypothèses sur nos données qui permettront à une procédure mathématique de produire des valeurs estimées pour α et β. Ces estimateurs, appelés α et β, basés sur les données de l’échantillon agissent alors comme des estimateurs pour leurs paramètres de population équivalents, α et β respectivement. Les quatre hypothèses qui permettent d’utiliser les données de l’échantillon pour estimer les données de la population sont (i) la normalité, (ii) l’homogénéité, (iii) l’indépendance et (iv) la fixité de X.\n\n3.1.1 Normalité\nL’hypothèse de normalité signifie que si nous répétons l’échantillonnage plusieurs fois dans les mêmes conditions environnementales, les observations seront normalement distribuées pour chaque valeur de X."
  }
]